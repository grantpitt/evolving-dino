{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-small\")\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-small\")\n",
    "model = model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = Image.open(\"./grant-headshot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_vects(imgs):\n",
    "    inputs = processor(images=imgs, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(\"mps\") for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    # vects = outputs.last_hidden_state.mean(axis=1).detach().cpu().numpy()\n",
    "    vects = outputs.last_hidden_state[:, 1:, :].detach().cpu().numpy()\n",
    "    # normalize\n",
    "    # vects /= np.linalg.norm(vects, axis=1, keepdims=True)\n",
    "    return vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/functional.py:3967: UserWarning: The operator 'aten::upsample_bicubic2d.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)\n"
     ]
    }
   ],
   "source": [
    "target_vect = get_img_vects(target_img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 4, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535b1e8d9bdf4454a4bf9e96dce63673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m g_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     44\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m criterion(generator(torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, input_size)))\n\u001b[0;32m---> 45\u001b[0m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m g_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Train discriminator\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# d_optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# d_loss = criterion(discriminator(batch))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Show progress\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 100  # Size of the noise vector\n",
    "hidden_dim = 128\n",
    "img_size = 32\n",
    "output_size = img_size * img_size  # Assuming we're generating images of size 32x32\n",
    "learning_rate = 0.0002\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(input_size, hidden_dim, output_size)\n",
    "# discriminator = Discriminator(output_size, hidden_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "# d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "def criterion(x):\n",
    "    # Convert individual to image\n",
    "    x = x.detach().cpu().numpy().astype(np.uint8).reshape(-1, img_size, img_size).astype(np.uint8)\n",
    "\n",
    "    imgs = []\n",
    "    for i in range(len(x)):\n",
    "        img = Image.fromarray(x[i] * 255).convert(\"RGB\")\n",
    "        # img.save(f\"gen_img_{i}.png\")\n",
    "        imgs.append(img)\n",
    "\n",
    "    # Calculate similarity to target image (placeholder function)\n",
    "    img_vects = get_img_vects(imgs)\n",
    "    errs = ((img_vects - target_vect) ** 2).mean(axis=-1).mean(axis=-1)\n",
    "    return torch.tensor(errs)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(epochs))\n",
    "# Training loop\n",
    "for epoch in pbar:\n",
    "    # for i in range(0, len(train_data), batch_size):\n",
    "        # Load a batch & transform to vectors\n",
    "        # batch = train_data[i:i+batch_size]\n",
    "        # batch = get_img_vects(batch)\n",
    "        # Train generator\n",
    "    g_optimizer.zero_grad()\n",
    "    g_loss = criterion(generator(torch.randn(batch_size, input_size)))\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    # Train discriminator\n",
    "    # d_optimizer.zero_grad()\n",
    "    # d_loss = criterion(discriminator(batch))\n",
    "    # d_loss.backward()\n",
    "    # d_optimizer.step()\n",
    "\n",
    "    # Show progress\n",
    "    pbar.update(1)\n",
    "    pbar.set_description(f\"Epoch [{epoch}/{epochs}], g_loss: {g_loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# Save the model\n",
    "# torch.save(generator.state_dict(), \"generator.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 4, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 100  # Size of the noise vector\n",
    "hidden_dim = 128\n",
    "output_size = 32 * 32  # Assuming we're generating images of size 32x32\n",
    "learning_rate = 0.0002\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(input_size, hidden_dim, output_size)\n",
    "discriminator = Discriminator(output_size, hidden_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch in DataLoader:  # Assuming 'DataLoader' is defined and loaded with your image dataset\n",
    "        # Train discriminator\n",
    "        real_images = batch\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        fake_images = generator(torch.randn(batch_size, input_size))\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        real_loss = criterion(discriminator(real_images), real_labels)\n",
    "        fake_loss = criterion(discriminator(fake_images.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train generator\n",
    "        g_optimizer.zero_grad()\n",
    "        fake_images = generator(torch.randn(batch_size, input_size))\n",
    "        g_loss = criterion(discriminator(fake_images), real_labels)  # Trick discriminator\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | D Loss: {d_loss.item()} | G Loss: {g_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
